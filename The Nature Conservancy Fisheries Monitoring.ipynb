{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import py7zlib\n",
    "import shutil\n",
    "import hashlib\n",
    "from tqdm import tqdm_notebook\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_dir = 'data'\n",
    "\n",
    "train_path = 'train.zip'\n",
    "test_stg1_path = 'test_stg1.zip'\n",
    "test_stg2_path = 'test_stg2.7z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_base_dir):\n",
    "    os.makedirs(data_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip(zip_path, out_dir):\n",
    "    #if not os.path.exists(out_dir):\n",
    "    name = os.path.basename(zip_path).split('.')[0]\n",
    "    zip_ref = zipfile.ZipFile(zip_path, 'r')\n",
    "    zip_ref.extractall(out_dir)\n",
    "    zip_ref.close()\n",
    "    return os.path.join(out_dir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract training data\n",
    "orig_train_dir = extract_zip(train_path, data_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract stage_1 test data\n",
    "test_stg1_dir  = extract_zip(test_stg1_path, os.path.join(data_base_dir, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import subprocess\n",
    "subprocess.call(r'\"C:\\Program Files\\7-Zip\\7z.exe\" x ' + test_stg2_path + ' -o' + data_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stg2_dir = os.path.join(data_base_dir, 'test_stg2')\n",
    "\n",
    "for img in os.listdir(test_stg2_dir):\n",
    "    shutil.move(os.path.join(test_stg2_dir, img), test_stg1_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass SevenZFile(object):\\n    \\n    def __init__(self, filepath):\\n        fp = open(filepath, 'rb')\\n        self.archive = py7zlib.Archive7z(fp)\\n        \\n    def is_7zfile(cls, filepath):\\n        is7z = False\\n        fp = None\\n        try:\\n            fp = open(filepath, 'rb')\\n            archive = py7zlib.Archive7z(fp)\\n            n = len(archive.getnames())\\n            is7z = True\\n        finally:\\n            if fp:\\n                fp.close()\\n        return is7z\\n\\n    def extractall(self, path):\\n        for name in tqdm_notebook(self.archive.getnames()):\\n            outfilename = os.path.join(path, name)\\n            outdir = os.path.dirname(outfilename)\\n            if not os.path.exists(outdir):\\n                os.makedirs(outdir)\\n            outfile = open(outfilename, 'wb')\\n            outfile.write(self.archive.getmember(name).read())\\n            outfile.close()\\nSevenZFile(test_stg2_path).extractall(data_base_dir)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract stage_1 test data\n",
    "# this takes forever to run, if you are in a hurry, extract it using the 7zip software\n",
    "\"\"\"\n",
    "class SevenZFile(object):\n",
    "    \n",
    "    def __init__(self, filepath):\n",
    "        fp = open(filepath, 'rb')\n",
    "        self.archive = py7zlib.Archive7z(fp)\n",
    "        \n",
    "    def is_7zfile(cls, filepath):\n",
    "        is7z = False\n",
    "        fp = None\n",
    "        try:\n",
    "            fp = open(filepath, 'rb')\n",
    "            archive = py7zlib.Archive7z(fp)\n",
    "            n = len(archive.getnames())\n",
    "            is7z = True\n",
    "        finally:\n",
    "            if fp:\n",
    "                fp.close()\n",
    "        return is7z\n",
    "\n",
    "    def extractall(self, path):\n",
    "        for name in tqdm_notebook(self.archive.getnames()):\n",
    "            outfilename = os.path.join(path, name)\n",
    "            outdir = os.path.dirname(outfilename)\n",
    "            if not os.path.exists(outdir):\n",
    "                os.makedirs(outdir)\n",
    "            outfile = open(outfilename, 'wb')\n",
    "            outfile.write(self.archive.getmember(name).read())\n",
    "            outfile.close()\n",
    "SevenZFile(test_stg2_path).extractall(data_base_dir)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = os.path.join(data_base_dir, 'train_val_split', 'training')\n",
    "validation_dir = os.path.join(data_base_dir, 'train_val_split', 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [class_ for class_ in os.listdir(orig_train_dir) if os.path.isdir(os.path.join(orig_train_dir, class_))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_ in classes:\n",
    "    \n",
    "    class_orig_dir = os.path.join(orig_train_dir, class_)\n",
    "    class_training_dir = os.path.join(training_dir, class_)\n",
    "    class_validation_dir = os.path.join(validation_dir, class_)\n",
    "    \n",
    "    if not os.path.exists(class_training_dir):\n",
    "        os.makedirs(class_training_dir)\n",
    "        \n",
    "    if not os.path.exists(class_validation_dir):\n",
    "        os.makedirs(class_validation_dir)\n",
    "\n",
    "    img_list = os.listdir(class_orig_dir)\n",
    "\n",
    "    for img in img_list:\n",
    "        hash_name = hashlib.sha1(img.encode('ascii'))\n",
    "        if int(hash_name.hexdigest(), 16) % 1000 > 100:\n",
    "            shutil.copy(os.path.join(class_orig_dir, img), class_training_dir)\n",
    "        else:\n",
    "            shutil.copy(os.path.join(class_orig_dir, img), class_validation_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning InceptionResnetV2 (trained on imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_base = InceptionResNetV2(include_top=False) #VGG16(include_top=False) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(conv_base)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=1e-4), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpointer = ModelCheckpoint('quicksign_inception_resnet_512.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "validation_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3393 images belonging to 8 classes.\n",
      "Found 384 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_data_gen.flow_from_directory(training_dir,\n",
    "                                                    target_size=(512, 512),\n",
    "                                                    batch_size=16,\n",
    "                                                    class_mode='categorical')\n",
    "validation_generator = validation_data_gen.flow_from_directory(validation_dir,\n",
    "                                                    target_size=(512, 512),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 276s - loss: 1.5224 - acc: 0.4575 - val_loss: 1.5335 - val_acc: 0.5078\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.53354, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 2/20\n",
      " - 269s - loss: 1.5041 - acc: 0.4586 - val_loss: 1.4945 - val_acc: 0.5182\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.53354 to 1.49449, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 3/20\n",
      " - 268s - loss: 1.4728 - acc: 0.4736 - val_loss: 1.4541 - val_acc: 0.5286\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.49449 to 1.45407, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 4/20\n",
      " - 267s - loss: 1.4443 - acc: 0.4789 - val_loss: 1.4424 - val_acc: 0.5417\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.45407 to 1.44240, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 5/20\n",
      " - 270s - loss: 1.4214 - acc: 0.4982 - val_loss: 1.4376 - val_acc: 0.5182\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.44240 to 1.43760, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 6/20\n",
      " - 269s - loss: 1.4177 - acc: 0.5035 - val_loss: 1.4137 - val_acc: 0.5339\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.43760 to 1.41365, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 7/20\n",
      " - 266s - loss: 1.3964 - acc: 0.5056 - val_loss: 1.4360 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.41365\n",
      "Epoch 8/20\n",
      " - 267s - loss: 1.3746 - acc: 0.5170 - val_loss: 1.4190 - val_acc: 0.4896\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.41365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28725c1d898>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, epochs=20, validation_data=validation_generator, verbose=2,\n",
    "                    callbacks=[checkpointer, earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('quicksign_inception_resnet_512.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if 'conv_7b' in layer.name:\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=1e-5), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 292s - loss: 1.2777 - acc: 0.5622 - val_loss: 1.2595 - val_acc: 0.5677\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.31421 to 1.25952, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 2/100\n",
      " - 282s - loss: 1.2359 - acc: 0.5754 - val_loss: 1.2148 - val_acc: 0.5729\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.25952 to 1.21477, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 3/100\n",
      " - 278s - loss: 1.1923 - acc: 0.5857 - val_loss: 1.1703 - val_acc: 0.5885\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.21477 to 1.17029, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 4/100\n",
      " - 283s - loss: 1.1662 - acc: 0.5930 - val_loss: 1.1449 - val_acc: 0.5911\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.17029 to 1.14490, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 5/100\n",
      " - 280s - loss: 1.1250 - acc: 0.5971 - val_loss: 1.1133 - val_acc: 0.6120\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.14490 to 1.11333, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 6/100\n",
      " - 277s - loss: 1.0926 - acc: 0.6144 - val_loss: 1.0848 - val_acc: 0.6120\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.11333 to 1.08477, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 7/100\n",
      " - 299s - loss: 1.0729 - acc: 0.6194 - val_loss: 1.0676 - val_acc: 0.6302\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.08477 to 1.06757, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 8/100\n",
      " - 294s - loss: 1.0547 - acc: 0.6247 - val_loss: 1.0495 - val_acc: 0.6406\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.06757 to 1.04951, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 9/100\n",
      " - 294s - loss: 1.0296 - acc: 0.6358 - val_loss: 1.0282 - val_acc: 0.6458\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.04951 to 1.02818, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 10/100\n",
      " - 286s - loss: 0.9947 - acc: 0.6452 - val_loss: 1.0040 - val_acc: 0.6510\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.02818 to 1.00401, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 11/100\n",
      " - 273s - loss: 0.9919 - acc: 0.6497 - val_loss: 0.9917 - val_acc: 0.6693\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.00401 to 0.99172, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 12/100\n",
      " - 268s - loss: 0.9700 - acc: 0.6602 - val_loss: 0.9803 - val_acc: 0.6719\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.99172 to 0.98028, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 13/100\n",
      " - 271s - loss: 0.9463 - acc: 0.6731 - val_loss: 0.9530 - val_acc: 0.6745\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.98028 to 0.95302, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 14/100\n",
      " - 273s - loss: 0.9489 - acc: 0.6593 - val_loss: 0.9440 - val_acc: 0.6849\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.95302 to 0.94403, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 15/100\n",
      " - 275s - loss: 0.9304 - acc: 0.6775 - val_loss: 0.9329 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.94403 to 0.93292, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 16/100\n",
      " - 249s - loss: 0.8991 - acc: 0.6895 - val_loss: 0.9200 - val_acc: 0.6953\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.93292 to 0.91999, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 17/100\n",
      " - 252s - loss: 0.8871 - acc: 0.7022 - val_loss: 0.9042 - val_acc: 0.7031\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.91999 to 0.90423, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 18/100\n",
      " - 249s - loss: 0.8909 - acc: 0.6869 - val_loss: 0.8899 - val_acc: 0.6979\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.90423 to 0.88990, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 19/100\n",
      " - 251s - loss: 0.8860 - acc: 0.6931 - val_loss: 0.8742 - val_acc: 0.6979\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.88990 to 0.87423, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 20/100\n",
      " - 252s - loss: 0.8650 - acc: 0.7042 - val_loss: 0.8629 - val_acc: 0.7057\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.87423 to 0.86287, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 21/100\n",
      " - 252s - loss: 0.8513 - acc: 0.7154 - val_loss: 0.8535 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.86287 to 0.85353, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 22/100\n",
      " - 253s - loss: 0.8380 - acc: 0.7180 - val_loss: 0.8447 - val_acc: 0.7057\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.85353 to 0.84468, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 23/100\n",
      " - 252s - loss: 0.8225 - acc: 0.7283 - val_loss: 0.8303 - val_acc: 0.7161\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.84468 to 0.83031, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 24/100\n",
      " - 253s - loss: 0.8149 - acc: 0.7230 - val_loss: 0.8276 - val_acc: 0.7188\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.83031 to 0.82764, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 25/100\n",
      " - 252s - loss: 0.8041 - acc: 0.7236 - val_loss: 0.8116 - val_acc: 0.7135\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.82764 to 0.81158, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 26/100\n",
      " - 250s - loss: 0.7921 - acc: 0.7342 - val_loss: 0.8062 - val_acc: 0.7214\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.81158 to 0.80617, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 27/100\n",
      " - 252s - loss: 0.7949 - acc: 0.7359 - val_loss: 0.8047 - val_acc: 0.7318\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.80617 to 0.80466, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 28/100\n",
      " - 253s - loss: 0.7807 - acc: 0.7306 - val_loss: 0.7873 - val_acc: 0.7448\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.80466 to 0.78729, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 29/100\n",
      " - 253s - loss: 0.7720 - acc: 0.7456 - val_loss: 0.7868 - val_acc: 0.7396\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.78729 to 0.78676, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 30/100\n",
      " - 255s - loss: 0.7676 - acc: 0.7409 - val_loss: 0.7738 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.78676 to 0.77382, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 31/100\n",
      " - 269s - loss: 0.7493 - acc: 0.7476 - val_loss: 0.7638 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.77382 to 0.76378, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 32/100\n",
      " - 275s - loss: 0.7350 - acc: 0.7629 - val_loss: 0.7618 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.76378 to 0.76179, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 33/100\n",
      " - 273s - loss: 0.7423 - acc: 0.7550 - val_loss: 0.7584 - val_acc: 0.7526\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.76179 to 0.75845, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 34/100\n",
      " - 268s - loss: 0.7431 - acc: 0.7644 - val_loss: 0.7481 - val_acc: 0.7552\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.75845 to 0.74813, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 35/100\n",
      " - 268s - loss: 0.7355 - acc: 0.7620 - val_loss: 0.7415 - val_acc: 0.7552\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.74813 to 0.74154, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 36/100\n",
      " - 280s - loss: 0.7042 - acc: 0.7673 - val_loss: 0.7327 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.74154 to 0.73272, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 37/100\n",
      " - 278s - loss: 0.7069 - acc: 0.7664 - val_loss: 0.7295 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.73272 to 0.72953, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 38/100\n",
      " - 272s - loss: 0.6966 - acc: 0.7752 - val_loss: 0.7185 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.72953 to 0.71849, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 39/100\n",
      " - 275s - loss: 0.7081 - acc: 0.7603 - val_loss: 0.7185 - val_acc: 0.7734\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.71849 to 0.71848, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 40/100\n",
      " - 270s - loss: 0.6698 - acc: 0.7896 - val_loss: 0.7011 - val_acc: 0.7839\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.71848 to 0.70113, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 41/100\n",
      " - 258s - loss: 0.6953 - acc: 0.7767 - val_loss: 0.7053 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.70113\n",
      "Epoch 42/100\n",
      " - 251s - loss: 0.6831 - acc: 0.7726 - val_loss: 0.6969 - val_acc: 0.7943\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.70113 to 0.69689, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 43/100\n",
      " - 251s - loss: 0.6906 - acc: 0.7711 - val_loss: 0.6932 - val_acc: 0.7995\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00043: val_loss improved from 0.69689 to 0.69321, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 44/100\n",
      " - 252s - loss: 0.6683 - acc: 0.7911 - val_loss: 0.6893 - val_acc: 0.7943\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.69321 to 0.68932, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 45/100\n",
      " - 250s - loss: 0.6594 - acc: 0.7905 - val_loss: 0.6835 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.68932 to 0.68347, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 46/100\n",
      " - 251s - loss: 0.6476 - acc: 0.7923 - val_loss: 0.6781 - val_acc: 0.7891\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.68347 to 0.67809, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 47/100\n",
      " - 251s - loss: 0.6394 - acc: 0.7940 - val_loss: 0.6665 - val_acc: 0.8073\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.67809 to 0.66650, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 48/100\n",
      " - 248s - loss: 0.6370 - acc: 0.7893 - val_loss: 0.6710 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.66650\n",
      "Epoch 49/100\n",
      " - 254s - loss: 0.6488 - acc: 0.7914 - val_loss: 0.6675 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.66650\n",
      "Epoch 50/100\n",
      " - 250s - loss: 0.6371 - acc: 0.7934 - val_loss: 0.6636 - val_acc: 0.7995\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.66650 to 0.66359, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 51/100\n",
      " - 252s - loss: 0.6262 - acc: 0.7973 - val_loss: 0.6509 - val_acc: 0.8021\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.66359 to 0.65089, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 52/100\n",
      " - 251s - loss: 0.6156 - acc: 0.8046 - val_loss: 0.6494 - val_acc: 0.7917\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.65089 to 0.64937, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 53/100\n",
      " - 251s - loss: 0.6201 - acc: 0.7984 - val_loss: 0.6476 - val_acc: 0.8047\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.64937 to 0.64756, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 54/100\n",
      " - 253s - loss: 0.6013 - acc: 0.8137 - val_loss: 0.6395 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.64756 to 0.63951, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 55/100\n",
      " - 251s - loss: 0.6050 - acc: 0.8163 - val_loss: 0.6441 - val_acc: 0.8151\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.63951\n",
      "Epoch 56/100\n",
      " - 254s - loss: 0.5918 - acc: 0.8072 - val_loss: 0.6345 - val_acc: 0.8099\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.63951 to 0.63455, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 57/100\n",
      " - 252s - loss: 0.5969 - acc: 0.8078 - val_loss: 0.6336 - val_acc: 0.8099\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.63455 to 0.63364, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 58/100\n",
      " - 252s - loss: 0.5834 - acc: 0.8131 - val_loss: 0.6332 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.63364 to 0.63324, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 59/100\n",
      " - 249s - loss: 0.6009 - acc: 0.8075 - val_loss: 0.6221 - val_acc: 0.8281\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.63324 to 0.62210, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 60/100\n",
      " - 250s - loss: 0.5846 - acc: 0.8096 - val_loss: 0.6150 - val_acc: 0.8177\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.62210 to 0.61503, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 61/100\n",
      " - 252s - loss: 0.5841 - acc: 0.8148 - val_loss: 0.6191 - val_acc: 0.8177\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.61503\n",
      "Epoch 62/100\n",
      " - 253s - loss: 0.5612 - acc: 0.8219 - val_loss: 0.6161 - val_acc: 0.8255\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.61503\n",
      "Epoch 63/100\n",
      " - 254s - loss: 0.5680 - acc: 0.8151 - val_loss: 0.6097 - val_acc: 0.8281\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.61503 to 0.60970, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 64/100\n",
      " - 250s - loss: 0.5526 - acc: 0.8263 - val_loss: 0.6080 - val_acc: 0.8281\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.60970 to 0.60803, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 65/100\n",
      " - 252s - loss: 0.5755 - acc: 0.8234 - val_loss: 0.6070 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.60803 to 0.60699, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 66/100\n",
      " - 256s - loss: 0.5826 - acc: 0.8163 - val_loss: 0.5955 - val_acc: 0.8177\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.60699 to 0.59553, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 67/100\n",
      " - 251s - loss: 0.5466 - acc: 0.8292 - val_loss: 0.5983 - val_acc: 0.8281\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.59553\n",
      "Epoch 68/100\n",
      " - 254s - loss: 0.5639 - acc: 0.8178 - val_loss: 0.5989 - val_acc: 0.8177\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.59553\n",
      "Epoch 69/100\n",
      " - 252s - loss: 0.5617 - acc: 0.8319 - val_loss: 0.5925 - val_acc: 0.8255\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.59553 to 0.59247, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 70/100\n",
      " - 251s - loss: 0.5373 - acc: 0.8357 - val_loss: 0.5866 - val_acc: 0.8255\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.59247 to 0.58656, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 71/100\n",
      " - 253s - loss: 0.5424 - acc: 0.8260 - val_loss: 0.5847 - val_acc: 0.8281\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.58656 to 0.58470, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 72/100\n",
      " - 253s - loss: 0.5439 - acc: 0.8342 - val_loss: 0.5844 - val_acc: 0.8307\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.58470 to 0.58442, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 73/100\n",
      " - 252s - loss: 0.5264 - acc: 0.8380 - val_loss: 0.5815 - val_acc: 0.8307\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.58442 to 0.58146, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 74/100\n",
      " - 252s - loss: 0.5435 - acc: 0.8278 - val_loss: 0.5789 - val_acc: 0.8281\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.58146 to 0.57891, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 75/100\n",
      " - 256s - loss: 0.5496 - acc: 0.8260 - val_loss: 0.5690 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.57891 to 0.56897, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 76/100\n",
      " - 259s - loss: 0.5281 - acc: 0.8415 - val_loss: 0.5715 - val_acc: 0.8307\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.56897\n",
      "Epoch 77/100\n",
      " - 255s - loss: 0.5252 - acc: 0.8298 - val_loss: 0.5661 - val_acc: 0.8411\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.56897 to 0.56614, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 78/100\n",
      " - 253s - loss: 0.5395 - acc: 0.8348 - val_loss: 0.5630 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.56614 to 0.56296, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 79/100\n",
      " - 255s - loss: 0.5140 - acc: 0.8430 - val_loss: 0.5595 - val_acc: 0.8385\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.56296 to 0.55946, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 80/100\n",
      " - 255s - loss: 0.5229 - acc: 0.8410 - val_loss: 0.5615 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.55946\n",
      "Epoch 81/100\n",
      " - 256s - loss: 0.5187 - acc: 0.8448 - val_loss: 0.5575 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.55946 to 0.55751, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 82/100\n",
      " - 252s - loss: 0.5195 - acc: 0.8430 - val_loss: 0.5548 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.55751 to 0.55484, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 83/100\n",
      " - 252s - loss: 0.5105 - acc: 0.8430 - val_loss: 0.5540 - val_acc: 0.8385\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.55484 to 0.55401, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 84/100\n",
      " - 257s - loss: 0.5042 - acc: 0.8460 - val_loss: 0.5457 - val_acc: 0.8385\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.55401 to 0.54568, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 85/100\n",
      " - 255s - loss: 0.4989 - acc: 0.8459 - val_loss: 0.5445 - val_acc: 0.8385\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.54568 to 0.54454, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 86/100\n",
      " - 253s - loss: 0.5075 - acc: 0.8401 - val_loss: 0.5493 - val_acc: 0.8411\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.54454\n",
      "Epoch 87/100\n",
      " - 259s - loss: 0.4936 - acc: 0.8454 - val_loss: 0.5497 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.54454\n",
      "Epoch 88/100\n",
      " - 252s - loss: 0.4794 - acc: 0.8489 - val_loss: 0.5419 - val_acc: 0.8385\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00088: val_loss improved from 0.54454 to 0.54193, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 89/100\n",
      " - 253s - loss: 0.4992 - acc: 0.8457 - val_loss: 0.5341 - val_acc: 0.8411\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.54193 to 0.53405, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 90/100\n",
      " - 255s - loss: 0.4933 - acc: 0.8421 - val_loss: 0.5341 - val_acc: 0.8411\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.53405\n",
      "Epoch 91/100\n",
      " - 253s - loss: 0.4820 - acc: 0.8551 - val_loss: 0.5408 - val_acc: 0.8385\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.53405\n",
      "Epoch 92/100\n",
      " - 257s - loss: 0.4844 - acc: 0.8498 - val_loss: 0.5346 - val_acc: 0.8411\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.53405\n",
      "Epoch 93/100\n",
      " - 253s - loss: 0.4776 - acc: 0.8489 - val_loss: 0.5294 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.53405 to 0.52944, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 94/100\n",
      " - 258s - loss: 0.4766 - acc: 0.8557 - val_loss: 0.5255 - val_acc: 0.8385\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.52944 to 0.52547, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 95/100\n",
      " - 255s - loss: 0.4793 - acc: 0.8592 - val_loss: 0.5300 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.52547\n",
      "Epoch 96/100\n",
      " - 257s - loss: 0.4558 - acc: 0.8647 - val_loss: 0.5294 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.52547\n",
      "Epoch 97/100\n",
      " - 255s - loss: 0.4570 - acc: 0.8612 - val_loss: 0.5192 - val_acc: 0.8385\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.52547 to 0.51916, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 98/100\n",
      " - 258s - loss: 0.4636 - acc: 0.8615 - val_loss: 0.5183 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.51916 to 0.51826, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 99/100\n",
      " - 251s - loss: 0.4550 - acc: 0.8642 - val_loss: 0.5085 - val_acc: 0.8385\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.51826 to 0.50849, saving model to quicksign_inception_resnet_512.h5\n",
      "Epoch 100/100\n",
      " - 253s - loss: 0.4593 - acc: 0.8647 - val_loss: 0.5113 - val_acc: 0.8385\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.50849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x287262620b8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, epochs=100, validation_data=validation_generator, verbose=2,\n",
    "                    callbacks=[checkpointer, earlystopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13153 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_data_gen.flow_from_directory('data/test/',\n",
    "                                                    target_size=(512, 512),\n",
    "                                                    batch_size=64,\n",
    "                                                    class_mode='categorical',\n",
    "                                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - ETA: 41:3 - ETA: 25:3 - ETA: 20:0 - ETA: 17:2 - ETA: 15:4 - ETA: 14:3 - ETA: 13:4 - ETA: 13:0 - ETA: 12:3 - ETA: 12:1 - ETA: 11:5 - ETA: 11:3 - ETA: 11:2 - ETA: 11:0 - ETA: 10:5 - ETA: 10:4 - ETA: 10:3 - ETA: 10:2 - ETA: 10:1 - ETA: 10:1 - ETA: 10:0 - ETA: 9:5 - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 57s - ETA: 54 - ETA: 51 - ETA: 48 - ETA: 45 - ETA: 43 - ETA: 40 - ETA: 37 - ETA: 34 - ETA: 31 - ETA: 28 - ETA: 25 - ETA: 22 - ETA: 20 - ETA: 17 - ETA: 14 - ETA: 11 - ETA: 8 - ETA:  - ETA:  - 592s 3s/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict_generator(test_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13153, 8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "im_names = np.array(os.listdir(os.path.join('data/test', 'test_stg1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_names = ['test_stg2/'+name if 'image' in name else name for name in im_names ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = pd.DataFrame({'image': im_names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame(data=preds, columns=['ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.concat([df_names, df_preds], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
